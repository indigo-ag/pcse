import json
import os
import pandas as pd
from pcse.simulator.scripts.utils import analyze_cse_directory

# Update paths as necessary.
# `working_directory` should contain:
#      1. soil_sample_initial_snowflake.csv
#      2. RP4_post_processed_for_PCSE_dates_CAR1459_RP4_20240615.csv
# working_directory = '/Users/joshcarter/git/atlas-sees-eng/pcse_testing'
working_directory = "/tmp/pcse"
# `data_directory` should contain:
#      1. all PCSE input files generated by SEES (soils + weather + events)
data_directory = working_directory + "/input_files"

# An example of this file may be found at:
# s3://pcse-cal-val-development/RP4_Mock_Run/soil_sample_initial_snowflake.csv
initial_soc = pd.read_csv(
    os.path.join(working_directory, "soil_sample_initial_snowflake.csv")
)

# An example of this file may be found at:
# s3://pcse-cal-val-development/RP4_Mock_Run/RP4_post_processed_for_PCSE_dates_CAR1459_RP4_20240615.csv
RP4_dates = pd.read_csv(
    os.path.join(
        working_directory, "RP4_post_processed_for_PCSE_dates_CAR1459_RP4_20240615.csv"
    )
)

# Merge the two dataframes on point_id
merged_df_initial_soc = pd.merge(
    initial_soc, RP4_dates.rename(columns={"point_id": "POINT_ID"}), on="POINT_ID"
)

results = analyze_cse_directory(data_directory, merged_df_initial_soc)

# if run_map.json already exists, remove it
if os.path.exists(data_directory + "/Run_map.json"):
    print("deleting old Run_map.json")
    os.remove(data_directory + "/Run_map.json")
# write the results to a file
run_map_json_path = data_directory + "/Run_map.json"
with open(run_map_json_path, "w", encoding="utf-8") as f:
    json.dump(results, f, indent=2)

print(f"Run_map.json written to {run_map_json_path}")
